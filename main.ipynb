{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad740f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709550cd0b704ed4b7d33bba21ced7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.mp4,.avi,.mov', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5195d4bb9bc94ff1928f2b804ae87242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='Flouter les visages')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90eaf6261ca44fafaf0123534f9efbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='Flouter les plaques')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f5ce7f72e84952aad688e1fa60f48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=True, description='Flouter les Ã©crans')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6080dba23c94ebd83f2a3335c40d256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=3, description='IntensitÃ© du flou', max=5, min=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aad3850678d435daa54c5aa5240e8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Lancer le floutage', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43743e139bdd4842b5d838d631b042f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================\n",
    "# FLOUTAGE VIDÃ‰O INTELLIGENT - NOTEBOOK\n",
    "# =========================\n",
    "\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Video, display\n",
    "import ipywidgets as widgets\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# =========================\n",
    "# CHARGEMENT DES MODÃˆLES\n",
    "# =========================\n",
    "def charger_modeles():\n",
    "    return {\n",
    "        \"face\": YOLO(\"yolov8s-face-lindevs.pt\"),\n",
    "        \"alpr\": YOLO(\"best.pt\"),\n",
    "        \"coco\": YOLO(\"yolov8n.pt\")\n",
    "    }\n",
    "\n",
    "models = charger_modeles()\n",
    "OBJETS_COCO = [\"laptop\", \"cell phone\", \"tv\"]\n",
    "\n",
    "# =========================\n",
    "# FONCTIONS UTILITAIRES\n",
    "# =========================\n",
    "def clamp_bbox(bbox, shape):\n",
    "    x1, y1, x2, y2 = map(int, bbox)\n",
    "    x1 = max(0, x1); y1 = max(0, y1)\n",
    "    x2 = min(shape[1]-1, x2); y2 = min(shape[0]-1, y2)\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return None\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def flouter_roi(frame, bbox, intensite, ellipse=False):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    roi = frame[y1:y2, x1:x2]\n",
    "    if roi.size == 0:\n",
    "        return\n",
    "    k = max(15, ((x2-x1)//3)|1) * intensite\n",
    "    flou = cv2.GaussianBlur(roi, (k, k), 0)\n",
    "    if ellipse:\n",
    "        mask = np.zeros(roi.shape[:2], dtype=np.uint8)\n",
    "        cx, cy = (x2-x1)//2, (y2-y1)//2\n",
    "        rx = int((x2-x1) * 0.95 / 2)\n",
    "        ry = int((y2-y1) * 0.95 / 2)\n",
    "        cv2.ellipse(mask, (cx, cy), (rx, ry), 0, 0, 360, 255, -1)\n",
    "        roi[mask == 255] = flou[mask == 255]\n",
    "    else:\n",
    "        roi[:] = flou\n",
    "\n",
    "def cercle_progression(p):\n",
    "    values = [p, 100-p]\n",
    "    fig = go.Figure(go.Pie(\n",
    "        values=values,\n",
    "        hole=0.7,\n",
    "        textinfo=\"none\",\n",
    "        marker_colors=[\"#2f87df\", \"#a8c4ed\"],\n",
    "        sort=False,\n",
    "        direction=\"clockwise\",\n",
    "        rotation=90\n",
    "    ))\n",
    "    fig.update_layout(\n",
    "        width=150, height=150,\n",
    "        annotations=[dict(text=f\"{p}%\", x=0.5, y=0.5, showarrow=False, font_size=18)],\n",
    "        margin=dict(t=0,b=0,l=0,r=0),\n",
    "        paper_bgcolor=\"rgba(0,0,0,0)\"\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# =========================\n",
    "# PARAMÃˆTRES\n",
    "# =========================\n",
    "FRAME_STEP = 1\n",
    "MAX_MISSED = 1\n",
    "\n",
    "# =========================\n",
    "# TRAITEMENT VIDÃ‰O\n",
    "# =========================\n",
    "def traiter_video(video_bytes, use_face, use_alpr, use_coco, intensite_flou):\n",
    "    # Fichier temporaire\n",
    "    temp_in = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\")\n",
    "    temp_in.write(video_bytes)\n",
    "    temp_in.close()\n",
    "\n",
    "    cap = cv2.VideoCapture(temp_in.name)\n",
    "    w, h = int(cap.get(3)), int(cap.get(4))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    out_path =\"C:/Users/fatim/OneDrive/Bureau/VidÃ©os/video_floutÃ©e.mp4\"\n",
    "\n",
    "    out = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "    # âœ… Trackers persistant avec CSRT (compatible OpenCV rÃ©cent)\n",
    "    trackers = {\"face\": [], \"alpr\": [], \"coco\": []}\n",
    "    last_bboxes = {\"face\": [], \"alpr\": [], \"coco\": []}\n",
    "    missed = {\"face\": [], \"alpr\": [], \"coco\": []}\n",
    "    frame_id = 0\n",
    "\n",
    "    print(\"DÃ©but du traitement vidÃ©o...\")\n",
    "\n",
    "    for _ in tqdm(range(total), desc=\"Traitement des frames\"):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_id += 1\n",
    "\n",
    "        # ðŸ”µ DÃ©tection YOLO\n",
    "        if frame_id % FRAME_STEP == 0:\n",
    "            small = cv2.resize(frame, (640, int(640*h/w)))\n",
    "            for key, enabled, labels in [\n",
    "                (\"face\", use_face, None),\n",
    "                (\"alpr\", use_alpr, None),\n",
    "                (\"coco\", use_coco, OBJETS_COCO)\n",
    "            ]:\n",
    "                if not enabled:\n",
    "                    continue\n",
    "                result = models[key](small, conf=0.4, verbose=False)[0]\n",
    "                trackers[key] = []\n",
    "                last_bboxes[key] = []\n",
    "                missed[key] = []\n",
    "                for box, cls in zip(result.boxes.xyxy, result.boxes.cls):\n",
    "                    if labels and models[key].names[int(cls)] not in labels:\n",
    "                        continue\n",
    "                    bbox = [\n",
    "                        box[0]*w/640,\n",
    "                        box[1]*h/small.shape[0],\n",
    "                        box[2]*w/640,\n",
    "                        box[3]*h/small.shape[0]\n",
    "                    ]\n",
    "                    safe = clamp_bbox(bbox, frame.shape)\n",
    "                    if safe:\n",
    "                        flouter_roi(frame, safe, intensite_flou, ellipse=(key==\"face\"))\n",
    "                        tracker = cv2.TrackerCSRT_create()\n",
    "                        x1, y1, x2, y2 = safe\n",
    "                        tracker.init(frame, (x1, y1, x2-x1, y2-y1))\n",
    "                        trackers[key].append(tracker)\n",
    "                        last_bboxes[key].append(safe)\n",
    "                        missed[key].append(0)\n",
    "\n",
    "        # ðŸ”µ Tracking persistant\n",
    "        else:\n",
    "            for key in trackers:\n",
    "                new_trackers = []\n",
    "                new_bboxes = []\n",
    "                new_missed = []\n",
    "                for i, tr in enumerate(trackers[key]):\n",
    "                    ok, b = tr.update(frame)\n",
    "                    if ok:\n",
    "                        x, y, w0, h0 = map(int, b)\n",
    "                        safe = clamp_bbox((x, y, x+w0, y+h0), frame.shape)\n",
    "                        if safe:\n",
    "                            flouter_roi(frame, safe, intensite_flou, ellipse=(key==\"face\"))\n",
    "                            new_trackers.append(tr)\n",
    "                            new_bboxes.append(safe)\n",
    "                            new_missed.append(0)\n",
    "                    else:\n",
    "                        if i < len(last_bboxes[key]) and missed[key][i] < MAX_MISSED:\n",
    "                            safe = last_bboxes[key][i]\n",
    "                            flouter_roi(frame, safe, intensite_flou, ellipse=(key==\"face\"))\n",
    "                            new_trackers.append(tr)\n",
    "                            new_bboxes.append(safe)\n",
    "                            new_missed.append(missed[key][i]+1)\n",
    "                trackers[key] = new_trackers\n",
    "                last_bboxes[key] = new_bboxes\n",
    "                missed[key] = new_missed\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"âœ… Traitement terminÃ©. VidÃ©o sauvegardÃ©e dans : {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "# =========================\n",
    "# WIDGETS INTERACTIFS\n",
    "# =========================\n",
    "upload_widget = widgets.FileUpload(\n",
    "    accept=\".mp4,.avi,.mov\",\n",
    "    multiple=False\n",
    ")\n",
    "display(upload_widget)\n",
    "\n",
    "face_checkbox = widgets.Checkbox(value=True, description=\"Flouter les visages\")\n",
    "alpr_checkbox = widgets.Checkbox(value=True, description=\"Flouter les plaques\")\n",
    "coco_checkbox = widgets.Checkbox(value=True, description=\"Flouter les Ã©crans\")\n",
    "intensite_slider = widgets.IntSlider(value=3, min=1, max=5, step=1, description=\"IntensitÃ© du flou\")\n",
    "\n",
    "display(face_checkbox, alpr_checkbox, coco_checkbox, intensite_slider)\n",
    "\n",
    "process_button = widgets.Button(description=\"Lancer le floutage\")\n",
    "output_widget = widgets.Output()\n",
    "display(process_button, output_widget)\n",
    "\n",
    "# =========================\n",
    "# Fonction robuste upload\n",
    "# =========================\n",
    "def get_uploaded_file(upload_widget):\n",
    "    if len(upload_widget.value) == 0:\n",
    "        return None\n",
    "    val = upload_widget.value[0] if isinstance(upload_widget.value, tuple) else list(upload_widget.value.values())[0]\n",
    "    return val['content']\n",
    "\n",
    "# =========================\n",
    "# Bouton dÃ©clenchement\n",
    "# =========================\n",
    "def on_button_click(b):\n",
    "    with output_widget:\n",
    "        output_widget.clear_output()\n",
    "        video_bytes = get_uploaded_file(upload_widget)\n",
    "        if video_bytes is None:\n",
    "            print(\"âš ï¸ Veuillez uploader une vidÃ©o d'abord.\")\n",
    "            return\n",
    "        out_path = traiter_video(\n",
    "            video_bytes,\n",
    "            use_face=face_checkbox.value,\n",
    "            use_alpr=alpr_checkbox.value,\n",
    "            use_coco=coco_checkbox.value,\n",
    "            intensite_flou=intensite_slider.value\n",
    "        )\n",
    "\n",
    "process_button.on_click(on_button_click)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
